{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1xWfYT8LV789"},"outputs":[],"source":["#GENERALIZZAZIONE\n","\n","import numpy as np\n","import os\n","import torch\n","from PIL import Image\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset\n","from tensorflow import keras #to load the dataset\n","from torchvision import datasets, models, transforms\n","from torchsummary import summary #network summary\n","from torchvision.models import resnet50, ResNet50_Weights\n","import glob\n","from tqdm import tqdm\n","import PIL.Image\n","PIL.Image.MAX_IMAGE_PIXELS = 93312000000000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FTvPxesV79C"},"outputs":[],"source":["LABELS = ['malware']\n","\n","input_path = \"/Users/mario/OneDrive/Desktop/Magistrale 2° Anno - 1° Semestre/Progetto AI4C/prova1/\"\n","BATCH_SIZE = 32\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize((224,224)), \n","    transforms.ToTensor()\n","    ])\n","\n","test_ds = datasets.ImageFolder(input_path, data_transforms)\n","\n","dataloaders = {\n","    'test': torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MdtlAPsdV79D"},"outputs":[],"source":["device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","model = models.resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n","model.fc = nn.Sequential(\n","               nn.Linear(2048, 128),\n","               nn.ReLU(inplace=True),\n","               nn.Linear(128, 1), \n","               nn.Sigmoid()).to(device)\n","               \n","#We load the model saved before\n","model.load_state_dict(torch.load('/Users/mario/OneDrive/Desktop/resnet50.h5', map_location=torch.device('cpu')), strict= False)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.fc.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlNoKRYTV79E","outputId":"4b45587c-3dde-446d-8f38-80f6def1ce9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 0.4731, acc: 0.7188\n"]}],"source":["#Here we evaluate the ability to generalize of the Image Based network\n","count = 0\n","running_loss = 0.0\n","running_corrects = 0\n","\n","model.eval()\n","\n","for inputs, labels in dataloaders['test']:\n","    inputs = inputs.to(device)\n","    labels = labels.to(device).float()\n","    labels = torch.unsqueeze(labels, -1)\n","    outputs = model(inputs).float()\n","    loss = criterion(outputs, labels)\n","\n","    preds = torch.round(outputs)\n","    running_loss += loss.item() * inputs.size(0)\n","    running_corrects += torch.sum(preds == labels.data)\n","    count+=1\n","\n","epoch_loss = running_loss / (count*BATCH_SIZE)\n","epoch_acc = running_corrects.float() / (count*BATCH_SIZE)\n","\n","print('loss: {:.4f}, acc: {:.4f}'.format(epoch_loss, epoch_acc)) "]}],"metadata":{"kernelspec":{"display_name":"AI4C","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"e888c850277277dd5abf5e89c38b98352b28e635678503cbe4fb57217260e47f"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}